{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "7qzolDQDUt4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "HPC1HKYdUxkP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Preprocessed Data"
      ],
      "metadata": {
        "id": "4bityT4IUzXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'preprocessed_crime_data.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "8qV0nmHvU1fa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping Columns"
      ],
      "metadata": {
        "id": "h3ewVXpxU3jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Crime Count', 'Is Violent', 'DATE OCC'])"
      ],
      "metadata": {
        "id": "2OEn3NZYU58e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring All Features Are Numeric"
      ],
      "metadata": {
        "id": "JL1qQsuTU786"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
        "X = numeric_df.drop(columns=['Target']).values.astype('float32')\n",
        "y = numeric_df['Target'].values"
      ],
      "metadata": {
        "id": "7n8ryzzyU-Y9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "RbMd0khXVArD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'year' in numeric_df.columns:\n",
        "    train_mask = numeric_df['year'].isin([2020, 2021, 2022])\n",
        "    test_mask = numeric_df['year'].isin([2023, 2024])\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uuyNOjuSVEAS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping for LSTM (samples, 1, features) for Tabular Data"
      ],
      "metadata": {
        "id": "WD2cBq-RV3J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(-1, 1, X_test.shape[1])"
      ],
      "metadata": {
        "id": "8Og7sB5uV-qe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting to PyTorch Tensors"
      ],
      "metadata": {
        "id": "-NkAePUzWARE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "m-QmhEAnWDtU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining 10 Parameter Combinations"
      ],
      "metadata": {
        "id": "yMvhSagdWFP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_combinations = [\n",
        "    {'hidden_size': 64, 'num_layers': 2, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3},\n",
        "    {'hidden_size': 128, 'num_layers': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2},\n",
        "    {'hidden_size': 256, 'num_layers': 2, 'lr': 0.0001, 'batch_size': 128, 'dropout': 0.4},\n",
        "    {'hidden_size': 64, 'num_layers': 3, 'lr': 0.002, 'batch_size': 64, 'dropout': 0.3, 'weight_decay': 0.001},\n",
        "    {'hidden_size': 32, 'num_layers': 1, 'lr': 0.005, 'batch_size': 16, 'dropout': 0.1},\n",
        "    {'hidden_size': 128, 'num_layers': 2, 'lr': 0.0002, 'batch_size': 256, 'dropout': 0.5},\n",
        "    {'hidden_size': 512, 'num_layers': 1, 'lr': 0.0001, 'batch_size': 64, 'dropout': 0.3},\n",
        "    {'hidden_size': 64, 'num_layers': 2, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'weight_decay': 0.0001},\n",
        "    {'hidden_size': 256, 'num_layers': 3, 'lr': 0.0005, 'batch_size': 128, 'dropout': 0.4},\n",
        "    {'hidden_size': 128, 'num_layers': 1, 'lr': 0.002, 'batch_size': 64, 'dropout': 0.3}\n",
        "]"
      ],
      "metadata": {
        "id": "1obe79XNWJcC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Model"
      ],
      "metadata": {
        "id": "Qws3a3rOWLOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrimeLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                           dropout=dropout if num_layers > 1 else 0, bidirectional=True)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.bn(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "PolKTnGYWMM7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Evaluation Function"
      ],
      "metadata": {
        "id": "jJa9JHmOWPPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(params, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Initializing model\n",
        "    model = CrimeLSTM(\n",
        "        input_size=X_train_tensor.shape[2],\n",
        "        hidden_size=params['hidden_size'],\n",
        "        num_layers=params.get('num_layers', 1),\n",
        "        num_classes=2,\n",
        "        dropout=params.get('dropout', 0)\n",
        "    ).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=params['lr'],\n",
        "        weight_decay=params.get('weight_decay', 0)\n",
        "    )\n",
        "\n",
        "    # DataLoader\n",
        "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_data, batch_size=params['batch_size'], shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    max_epochs = 20\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Evaluation on test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.to(device))\n",
        "        _, predicted = torch.max(test_outputs, 1)\n",
        "        predicted = predicted.cpu().numpy()\n",
        "\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(classification_report(y_test, predicted, digits=6, zero_division=0))\n",
        "    accuracy = accuracy_score(y_test, predicted)\n",
        "    print(f\"Accuracy: {accuracy:.6f}\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "o_SjYXJHWSPh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running for Each Parameter Combination"
      ],
      "metadata": {
        "id": "SzoJnldPWfPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = 0\n",
        "best_params = None\n",
        "for i, params in enumerate(param_combinations, 1):\n",
        "    print(f\"\\n=== Testing Parameter Combination {i} ===\")\n",
        "    print(f\"Parameters: {params}\")\n",
        "    accuracy = train_and_evaluate(params, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor)\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_params = params\n",
        "    print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nBest Parameters: {best_params}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD-VbBtJWh2O",
        "outputId": "8295317b-4105-44e0-896a-bfb4880c1d85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Testing Parameter Combination 1 ===\n",
            "Parameters: {'hidden_size': 64, 'num_layers': 2, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "Epoch 1, Train Loss: 0.5149\n",
            "Epoch 2, Train Loss: 0.4795\n",
            "Epoch 3, Train Loss: 0.4712\n",
            "Epoch 4, Train Loss: 0.4631\n",
            "Epoch 5, Train Loss: 0.4594\n",
            "Epoch 6, Train Loss: 0.4521\n",
            "Epoch 7, Train Loss: 0.4466\n",
            "Epoch 8, Train Loss: 0.4392\n",
            "Epoch 9, Train Loss: 0.4372\n",
            "Epoch 10, Train Loss: 0.4324\n",
            "Epoch 11, Train Loss: 0.4258\n",
            "Epoch 12, Train Loss: 0.4220\n",
            "Epoch 13, Train Loss: 0.4202\n",
            "Epoch 14, Train Loss: 0.4176\n",
            "Epoch 15, Train Loss: 0.4149\n",
            "Epoch 16, Train Loss: 0.4146\n",
            "Epoch 17, Train Loss: 0.4144\n",
            "Epoch 18, Train Loss: 0.4139\n",
            "Epoch 19, Train Loss: 0.4115\n",
            "Epoch 20, Train Loss: 0.4112\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.828470  0.990652  0.902331     10804\n",
            "           1   0.677316  0.087315  0.154688      2428\n",
            "\n",
            "    accuracy                       0.824894     13232\n",
            "   macro avg   0.752893  0.538983  0.528510     13232\n",
            "weighted avg   0.800734  0.824894  0.765143     13232\n",
            "\n",
            "Accuracy: 0.824894\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 2 ===\n",
            "Parameters: {'hidden_size': 128, 'num_layers': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2}\n",
            "Epoch 1, Train Loss: 0.4949\n",
            "Epoch 2, Train Loss: 0.4696\n",
            "Epoch 3, Train Loss: 0.4662\n",
            "Epoch 4, Train Loss: 0.4626\n",
            "Epoch 5, Train Loss: 0.4581\n",
            "Epoch 6, Train Loss: 0.4561\n",
            "Epoch 7, Train Loss: 0.4531\n",
            "Epoch 8, Train Loss: 0.4484\n",
            "Epoch 9, Train Loss: 0.4408\n",
            "Epoch 10, Train Loss: 0.4384\n",
            "Epoch 11, Train Loss: 0.4367\n",
            "Epoch 12, Train Loss: 0.4337\n",
            "Epoch 13, Train Loss: 0.4342\n",
            "Epoch 14, Train Loss: 0.4315\n",
            "Epoch 15, Train Loss: 0.4296\n",
            "Epoch 16, Train Loss: 0.4282\n",
            "Epoch 17, Train Loss: 0.4278\n",
            "Epoch 18, Train Loss: 0.4282\n",
            "Epoch 19, Train Loss: 0.4265\n",
            "Epoch 20, Train Loss: 0.4265\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.828877  0.989911  0.902265     10804\n",
            "           1   0.668693  0.090610  0.159594      2428\n",
            "\n",
            "    accuracy                       0.824894     13232\n",
            "   macro avg   0.748785  0.540260  0.530929     13232\n",
            "weighted avg   0.799484  0.824894  0.765989     13232\n",
            "\n",
            "Accuracy: 0.824894\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 3 ===\n",
            "Parameters: {'hidden_size': 256, 'num_layers': 2, 'lr': 0.0001, 'batch_size': 128, 'dropout': 0.4}\n",
            "Epoch 1, Train Loss: 0.6414\n",
            "Epoch 2, Train Loss: 0.5432\n",
            "Epoch 3, Train Loss: 0.5091\n",
            "Epoch 4, Train Loss: 0.4991\n",
            "Epoch 5, Train Loss: 0.4912\n",
            "Epoch 6, Train Loss: 0.4872\n",
            "Epoch 7, Train Loss: 0.4840\n",
            "Epoch 8, Train Loss: 0.4795\n",
            "Epoch 9, Train Loss: 0.4768\n",
            "Epoch 10, Train Loss: 0.4729\n",
            "Epoch 11, Train Loss: 0.4702\n",
            "Epoch 12, Train Loss: 0.4663\n",
            "Epoch 13, Train Loss: 0.4641\n",
            "Epoch 14, Train Loss: 0.4616\n",
            "Epoch 15, Train Loss: 0.4605\n",
            "Epoch 16, Train Loss: 0.4571\n",
            "Epoch 17, Train Loss: 0.4529\n",
            "Epoch 18, Train Loss: 0.4513\n",
            "Epoch 19, Train Loss: 0.4482\n",
            "Epoch 20, Train Loss: 0.4452\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.820300  0.997131  0.900113     10804\n",
            "           1   0.686869  0.028007  0.053819      2428\n",
            "\n",
            "    accuracy                       0.819302     13232\n",
            "   macro avg   0.753584  0.512569  0.476966     13232\n",
            "weighted avg   0.795816  0.819302  0.744822     13232\n",
            "\n",
            "Accuracy: 0.819302\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 4 ===\n",
            "Parameters: {'hidden_size': 64, 'num_layers': 3, 'lr': 0.002, 'batch_size': 64, 'dropout': 0.3, 'weight_decay': 0.001}\n",
            "Epoch 1, Train Loss: 0.5016\n",
            "Epoch 2, Train Loss: 0.4800\n",
            "Epoch 3, Train Loss: 0.4793\n",
            "Epoch 4, Train Loss: 0.4791\n",
            "Epoch 5, Train Loss: 0.4795\n",
            "Epoch 6, Train Loss: 0.4799\n",
            "Epoch 7, Train Loss: 0.4794\n",
            "Epoch 8, Train Loss: 0.4796\n",
            "Epoch 9, Train Loss: 0.4796\n",
            "Epoch 10, Train Loss: 0.4795\n",
            "Epoch 11, Train Loss: 0.4794\n",
            "Epoch 12, Train Loss: 0.4794\n",
            "Epoch 13, Train Loss: 0.4796\n",
            "Epoch 14, Train Loss: 0.4798\n",
            "Epoch 15, Train Loss: 0.4795\n",
            "Epoch 16, Train Loss: 0.4795\n",
            "Epoch 17, Train Loss: 0.4795\n",
            "Epoch 18, Train Loss: 0.4794\n",
            "Epoch 19, Train Loss: 0.4795\n",
            "Epoch 20, Train Loss: 0.4798\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.816505  1.000000  0.898985     10804\n",
            "           1   0.000000  0.000000  0.000000      2428\n",
            "\n",
            "    accuracy                       0.816505     13232\n",
            "   macro avg   0.408253  0.500000  0.449492     13232\n",
            "weighted avg   0.666681  0.816505  0.734026     13232\n",
            "\n",
            "Accuracy: 0.816505\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 5 ===\n",
            "Parameters: {'hidden_size': 32, 'num_layers': 1, 'lr': 0.005, 'batch_size': 16, 'dropout': 0.1}\n",
            "Epoch 1, Train Loss: 0.4864\n",
            "Epoch 2, Train Loss: 0.4805\n",
            "Epoch 3, Train Loss: 0.4799\n",
            "Epoch 4, Train Loss: 0.4802\n",
            "Epoch 5, Train Loss: 0.4800\n",
            "Epoch 6, Train Loss: 0.4795\n",
            "Epoch 7, Train Loss: 0.4801\n",
            "Epoch 8, Train Loss: 0.4794\n",
            "Epoch 9, Train Loss: 0.4800\n",
            "Epoch 10, Train Loss: 0.4800\n",
            "Epoch 11, Train Loss: 0.4801\n",
            "Epoch 12, Train Loss: 0.4793\n",
            "Epoch 13, Train Loss: 0.4799\n",
            "Epoch 14, Train Loss: 0.4796\n",
            "Epoch 15, Train Loss: 0.4800\n",
            "Epoch 16, Train Loss: 0.4795\n",
            "Epoch 17, Train Loss: 0.4793\n",
            "Epoch 18, Train Loss: 0.4793\n",
            "Epoch 19, Train Loss: 0.4794\n",
            "Epoch 20, Train Loss: 0.4791\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.816553  0.999907  0.898976     10804\n",
            "           1   0.500000  0.000412  0.000823      2428\n",
            "\n",
            "    accuracy                       0.816505     13232\n",
            "   macro avg   0.658277  0.500160  0.449900     13232\n",
            "weighted avg   0.758467  0.816505  0.734170     13232\n",
            "\n",
            "Accuracy: 0.816505\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 6 ===\n",
            "Parameters: {'hidden_size': 128, 'num_layers': 2, 'lr': 0.0002, 'batch_size': 256, 'dropout': 0.5}\n",
            "Epoch 1, Train Loss: 0.7037\n",
            "Epoch 2, Train Loss: 0.5914\n",
            "Epoch 3, Train Loss: 0.5458\n",
            "Epoch 4, Train Loss: 0.5216\n",
            "Epoch 5, Train Loss: 0.5103\n",
            "Epoch 6, Train Loss: 0.4996\n",
            "Epoch 7, Train Loss: 0.4943\n",
            "Epoch 8, Train Loss: 0.4900\n",
            "Epoch 9, Train Loss: 0.4862\n",
            "Epoch 10, Train Loss: 0.4833\n",
            "Epoch 11, Train Loss: 0.4795\n",
            "Epoch 12, Train Loss: 0.4783\n",
            "Epoch 13, Train Loss: 0.4745\n",
            "Epoch 14, Train Loss: 0.4740\n",
            "Epoch 15, Train Loss: 0.4707\n",
            "Epoch 16, Train Loss: 0.4682\n",
            "Epoch 17, Train Loss: 0.4676\n",
            "Epoch 18, Train Loss: 0.4669\n",
            "Epoch 19, Train Loss: 0.4639\n",
            "Epoch 20, Train Loss: 0.4617\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.819829  0.996483  0.899566     10804\n",
            "           1   0.620000  0.025535  0.049051      2428\n",
            "\n",
            "    accuracy                       0.818319     13232\n",
            "   macro avg   0.719915  0.511009  0.474308     13232\n",
            "weighted avg   0.783162  0.818319  0.743501     13232\n",
            "\n",
            "Accuracy: 0.818319\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 7 ===\n",
            "Parameters: {'hidden_size': 512, 'num_layers': 1, 'lr': 0.0001, 'batch_size': 64, 'dropout': 0.3}\n",
            "Epoch 1, Train Loss: 0.5543\n",
            "Epoch 2, Train Loss: 0.4779\n",
            "Epoch 3, Train Loss: 0.4742\n",
            "Epoch 4, Train Loss: 0.4675\n",
            "Epoch 5, Train Loss: 0.4648\n",
            "Epoch 6, Train Loss: 0.4634\n",
            "Epoch 7, Train Loss: 0.4595\n",
            "Epoch 8, Train Loss: 0.4553\n",
            "Epoch 9, Train Loss: 0.4512\n",
            "Epoch 10, Train Loss: 0.4496\n",
            "Epoch 11, Train Loss: 0.4457\n",
            "Epoch 12, Train Loss: 0.4415\n",
            "Epoch 13, Train Loss: 0.4358\n",
            "Epoch 14, Train Loss: 0.4331\n",
            "Epoch 15, Train Loss: 0.4308\n",
            "Epoch 16, Train Loss: 0.4267\n",
            "Epoch 17, Train Loss: 0.4222\n",
            "Epoch 18, Train Loss: 0.4218\n",
            "Epoch 19, Train Loss: 0.4190\n",
            "Epoch 20, Train Loss: 0.4150\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.831819  0.982877  0.901061     10804\n",
            "           1   0.603004  0.115733  0.194195      2428\n",
            "\n",
            "    accuracy                       0.823761     13232\n",
            "   macro avg   0.717412  0.549305  0.547628     13232\n",
            "weighted avg   0.789833  0.823761  0.771355     13232\n",
            "\n",
            "Accuracy: 0.823761\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 8 ===\n",
            "Parameters: {'hidden_size': 64, 'num_layers': 2, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'weight_decay': 0.0001}\n",
            "Epoch 1, Train Loss: 0.4986\n",
            "Epoch 2, Train Loss: 0.4769\n",
            "Epoch 3, Train Loss: 0.4740\n",
            "Epoch 4, Train Loss: 0.4712\n",
            "Epoch 5, Train Loss: 0.4699\n",
            "Epoch 6, Train Loss: 0.4701\n",
            "Epoch 7, Train Loss: 0.4686\n",
            "Epoch 8, Train Loss: 0.4691\n",
            "Epoch 9, Train Loss: 0.4691\n",
            "Epoch 10, Train Loss: 0.4686\n",
            "Epoch 11, Train Loss: 0.4674\n",
            "Epoch 12, Train Loss: 0.4680\n",
            "Epoch 13, Train Loss: 0.4699\n",
            "Epoch 14, Train Loss: 0.4722\n",
            "Epoch 15, Train Loss: 0.4682\n",
            "Epoch 16, Train Loss: 0.4661\n",
            "Epoch 17, Train Loss: 0.4650\n",
            "Epoch 18, Train Loss: 0.4741\n",
            "Epoch 19, Train Loss: 0.4708\n",
            "Epoch 20, Train Loss: 0.4673\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.816505  1.000000  0.898985     10804\n",
            "           1   0.000000  0.000000  0.000000      2428\n",
            "\n",
            "    accuracy                       0.816505     13232\n",
            "   macro avg   0.408253  0.500000  0.449492     13232\n",
            "weighted avg   0.666681  0.816505  0.734026     13232\n",
            "\n",
            "Accuracy: 0.816505\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 9 ===\n",
            "Parameters: {'hidden_size': 256, 'num_layers': 3, 'lr': 0.0005, 'batch_size': 128, 'dropout': 0.4}\n",
            "Epoch 1, Train Loss: 0.5630\n",
            "Epoch 2, Train Loss: 0.4896\n",
            "Epoch 3, Train Loss: 0.4788\n",
            "Epoch 4, Train Loss: 0.4709\n",
            "Epoch 5, Train Loss: 0.4639\n",
            "Epoch 6, Train Loss: 0.4568\n",
            "Epoch 7, Train Loss: 0.4516\n",
            "Epoch 8, Train Loss: 0.4473\n",
            "Epoch 9, Train Loss: 0.4406\n",
            "Epoch 10, Train Loss: 0.4359\n",
            "Epoch 11, Train Loss: 0.4302\n",
            "Epoch 12, Train Loss: 0.4276\n",
            "Epoch 13, Train Loss: 0.4194\n",
            "Epoch 14, Train Loss: 0.4165\n",
            "Epoch 15, Train Loss: 0.4131\n",
            "Epoch 16, Train Loss: 0.4103\n",
            "Epoch 17, Train Loss: 0.4092\n",
            "Epoch 18, Train Loss: 0.4085\n",
            "Epoch 19, Train Loss: 0.4069\n",
            "Epoch 20, Train Loss: 0.4057\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.845612  0.956127  0.897480     10804\n",
            "           1   0.533465  0.223229  0.314750      2428\n",
            "\n",
            "    accuracy                       0.821644     13232\n",
            "   macro avg   0.689538  0.589678  0.606115     13232\n",
            "weighted avg   0.788335  0.821644  0.790553     13232\n",
            "\n",
            "Accuracy: 0.821644\n",
            "================================================================================\n",
            "\n",
            "=== Testing Parameter Combination 10 ===\n",
            "Parameters: {'hidden_size': 128, 'num_layers': 1, 'lr': 0.002, 'batch_size': 64, 'dropout': 0.3}\n",
            "Epoch 1, Train Loss: 0.5017\n",
            "Epoch 2, Train Loss: 0.4828\n",
            "Epoch 3, Train Loss: 0.4766\n",
            "Epoch 4, Train Loss: 0.4731\n",
            "Epoch 5, Train Loss: 0.4697\n",
            "Epoch 6, Train Loss: 0.4640\n",
            "Epoch 7, Train Loss: 0.4657\n",
            "Epoch 8, Train Loss: 0.4623\n",
            "Epoch 9, Train Loss: 0.4647\n",
            "Epoch 10, Train Loss: 0.4605\n",
            "Epoch 11, Train Loss: 0.4610\n",
            "Epoch 12, Train Loss: 0.4595\n",
            "Epoch 13, Train Loss: 0.4595\n",
            "Epoch 14, Train Loss: 0.4570\n",
            "Epoch 15, Train Loss: 0.4655\n",
            "Epoch 16, Train Loss: 0.4706\n",
            "Epoch 17, Train Loss: 0.4662\n",
            "Epoch 18, Train Loss: 0.4596\n",
            "Epoch 19, Train Loss: 0.4573\n",
            "Epoch 20, Train Loss: 0.4507\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.817762  0.998889  0.899296     10804\n",
            "           1   0.657143  0.009473  0.018676      2428\n",
            "\n",
            "    accuracy                       0.817337     13232\n",
            "   macro avg   0.737452  0.504181  0.458986     13232\n",
            "weighted avg   0.788289  0.817337  0.737707     13232\n",
            "\n",
            "Accuracy: 0.817337\n",
            "================================================================================\n",
            "\n",
            "Best Parameters: {'hidden_size': 64, 'num_layers': 2, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "Best Accuracy: 0.824894\n"
          ]
        }
      ]
    }
  ]
}